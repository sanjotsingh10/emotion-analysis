{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion_analysis_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R2XdqKO0tUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install emoji\n",
        "pip install scikit-multilearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAi6Aj_gCyFb",
        "colab_type": "text"
      },
      "source": [
        "Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS3RyyL1A3eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "import emoji\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--wM1wI907Ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data= pd.read_csv(\"2018-E-c-En-train.txt\", sep=\"\\t\", header=0)\n",
        "dev_data= pd.read_csv(\"2018-E-c-En-dev.txt\", sep=\"\\t\", header=0)\n",
        "test_data= pd.read_csv(\"2018-E-c-En-test-gold.txt\", sep=\"\\t\", header=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zK3Rqa_dLqJq",
        "colab_type": "text"
      },
      "source": [
        "Show the number of emotions present in the tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5vk7OTPGqtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotions=list(train_data.head(0))\n",
        "emotions = emotions[2:]\n",
        "values=[]\n",
        "for column in emotions:\n",
        "    values.append(train_data[column].value_counts()[1])\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5)) \n",
        "\n",
        "# creating the bar plot \n",
        "plt.bar(emotions, values, color ='blue',width = 0.4)\n",
        "plt.ylabel(\"no of tweets\") \n",
        "plt.xlabel(\"emotions\") \n",
        "plt.title(\"Number of emotions present in tweets\") \n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftu1RtFsMGvu",
        "colab_type": "text"
      },
      "source": [
        "cleaning the text an performing lematization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0W1MttaxP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  text = text.lower()\n",
        "  \"\"\"make text url free\"\"\"\n",
        "  text = re.sub(r'http\\S+',\"\",text)\n",
        "\n",
        "  \"\"\"changing emoji to text\"\"\"\n",
        "  for word in text:\n",
        "      if word in emoji.UNICODE_EMOJI:\n",
        "          text = re.sub(r'('+word+')', emoji.demojize(word).replace('_',' ')+' ', text)\n",
        "\n",
        "  \"\"\"removing punctuations like  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"\n",
        "  cleaned_text = text.translate(str.maketrans('','',string.punctuation))\n",
        "  \"\"\"lemmatization\"\"\"\n",
        "  cleaned_text= \" \".join([lemmatizer.lemmatize(word) for word in cleaned_text.split()])\n",
        "  return(cleaned_text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uni3AmihbZcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ind in train_data.index: \n",
        "      train_data.loc[ind,'Tweet']= clean_text(train_data['Tweet'][ind])\n",
        "for ind in dev_data.index: \n",
        "      dev_data.loc[ind,'Tweet']= clean_text(dev_data['Tweet'][ind])\n",
        "for ind in test_data.index: \n",
        "      test_data.loc[ind,'Tweet']= clean_text(test_data['Tweet'][ind])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXkjKyOth4vn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train_data[\"ID\"]\n",
        "del dev_data[\"ID\"]\n",
        "del test_data[\"ID\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES7G9F8w7nue",
        "colab_type": "text"
      },
      "source": [
        "Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWQ2ZhoS7r6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = train_data[\"Tweet\"]\n",
        "test_text = test_data[\"Tweet\"]\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
        "vectorizer.fit(train_text)\n",
        "vectorizer.fit(test_text)\n",
        "#transform vetor\n",
        "x_train = vectorizer.transform(train_text)\n",
        "y_train = train_data.drop(labels = ['Tweet'], axis=1)\n",
        "\n",
        "x_test = vectorizer.transform(test_text)\n",
        "y_test = test_data.drop(labels = ['Tweet'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7VTIINGCHP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "sum = 0\n",
        "LogReg_pipeline = Pipeline([\n",
        "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
        "            ])\n",
        "for emotion in emotions:\n",
        "    print('**Processing {} comments...**'.format(emotion))\n",
        "    \n",
        "    # Training logistic regression model on train data\n",
        "    LogReg_pipeline.fit(x_train, train_data[emotion])\n",
        "    \n",
        "    # calculating test accuracy\n",
        "    prediction = LogReg_pipeline.predict(x_test)\n",
        "    #print(prediction)\n",
        "    #print(prediction.shape)\n",
        "    print('Test accuracy is {}%'.format(accuracy_score(test_data[emotion], prediction)*100))\n",
        "    sum = sum + accuracy_score(test_data[emotion], prediction) * 100\n",
        "    print(\"\\n\")\n",
        "sum = sum/11\n",
        "print(f\"average accuracy:{sum}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYTv8Xr7dWik",
        "colab_type": "text"
      },
      "source": [
        "predicting a text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNWEA5Pk3ZMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "7e340cc1-893f-422c-cf08-3dd53f7b7706"
      },
      "source": [
        "cleaned_text=clean_text(input(\"enter the text:\"))\n",
        "text = [cleaned_text]\n",
        "x_text = vectorizer.transform(text)\n",
        "\n",
        "for emotion in emotions:\n",
        "  LogReg_pipeline.fit(x_train, train_data[emotion])\n",
        "  prediction = LogReg_pipeline.predict(x_text)\n",
        "  if prediction[0] == 1:\n",
        "    print(f\"{emotion}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enter the tweet:i love everyone\n",
            "joy\n",
            "love\n",
            "optimism\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}